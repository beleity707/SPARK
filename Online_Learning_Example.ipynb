{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.regression import LabeledPoint, LinearRegressionWithSGD, LinearRegressionModel, StreamingLinearRegressionWithSGD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>First we will start by split our dataset to use as several chunks in the stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file as Pandas\n",
    "Green_Taxi_DF = pd.read_csv(\"Green_Taxi_B7.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split it to files\n",
    "chunk1,chunk2,chunk3,chunk4 = np.array_split(Green_Taxi_DF, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the chunks to the directory that you will use for stream Data\n",
    "# In my case:\n",
    "# The Stream Train Folder is \"Stream_Folder/DataFiles/Train/\"\"\n",
    "# The Stream Test Folder is \"Stream_Folder/DataFiles/Test/\"\n",
    "\n",
    "chunk1.to_csv(r'Stream_Folder/DataFiles/Train/chunk1.csv')\n",
    "chunk2.to_csv(r'Stream_Folder/DataFiles/Test/chunk2.csv')\n",
    "chunk3.to_csv(r'Stream_Folder/DataFiles/Test/chunk3.csv')\n",
    "chunk4.to_csv(r'Stream_Folder/DataFiles/Test/chunk4.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Now its time to use the Streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read starting \"Streaming linear regression\" <br>\n",
    "https://spark.apache.org/docs/1.6.2/mllib-linear-methods.html\n",
    "\n",
    "\n",
    "Read starting \"Streaming linear regression\" <br>\n",
    "https://spark.apache.org/docs/2.2.0/mllib-linear-methods.html#streaming-linear-regression\n",
    "\n",
    "\n",
    "Another good Example <br>\n",
    "https://github.com/apache/spark/blob/master/examples/src/main/python/mllib/streaming_linear_regression_example.py\n",
    "\n",
    "\n",
    "Read starting \"MLlib Operations\" <br>\n",
    "https://spark.apache.org/docs/2.2.0/streaming-programming-guide.html#mllib-operations\n",
    "\n",
    "\n",
    "Help <br>\n",
    "https://spark.apache.org/docs/2.1.3/api/python/pyspark.streaming.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Spark Streaming provides two categories of built-in streaming sources.</b>\n",
    "\n",
    "<b>Basic sources:</b> <br>\n",
    "Sources directly available in the StreamingContext API. Examples: file systems, and socket connections. \n",
    "\n",
    "<b>Advanced sources:</b> <br>\n",
    "Sources like Kafka, Flume, Kinesis, etc. are available through extra utility classes.\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .config('spark.master', 'local[4]') \\\n",
    "    .appName('Test') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc = StreamingContext(sc,batchDuration=30)\n",
    "\n",
    "#location = 'Stream_Folder/DataFiles/'\n",
    "#lines = ssc.textFileStream(\"Stream_Folder/DataFiles/chunk1.csv\").cache()\n",
    "\n",
    "##checkpointDir = \"/LOCAL_DIR/DATA/\"\n",
    "#ssc = StreamingContext.getActiveOrCreate(checkpointDir, creatingFunc)\n",
    "\n",
    "\n",
    "\n",
    "#lines = ssc.socketTextStream(\"localhost\", 9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(lp):\n",
    "    label = float(lp[lp.find('(') + 1: lp.find(',')])\n",
    "    vec = Vectors.dense(lp[lp.find('[') + 1: lp.find(']')].split(','))\n",
    "    return LabeledPoint(label, vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData = ssc.textFileStream(\"Stream_Folder/DataFiles/Train\").cache().map(parse).cache()\n",
    "testData = ssc.textFileStream(\"Stream_Folder/DataFiles/Test\")#.map(parse).cache()\n",
    "\n",
    "\n",
    "# The Stream Train Folder is \"Stream_Folder/DataFiles/Train/\"\"\n",
    "# The Stream Test Folder is \"Stream_Folder/DataFiles/Test/\"\n",
    "\n",
    "#trainingData = ssc.textFileStream(\"Stream_Folder/DataFiles/CheckPoints\").cache().map(parse).cache()\n",
    "#testData = ssc.textFileStream(\"Stream_Folder/DataFiles/DataFiles\")#.map(parse).cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will create a line with zero records instead of writting 12 zeros features \n",
    "# ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "\n",
    "numFeatures = 12\n",
    "zeroVector = Vectors.zeros(numFeatures)\n",
    "\n",
    "zeroVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StreamingLinearRegressionWithSGD()\n",
    "\n",
    "#.setInitialWeights([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "\n",
    "model.setInitialWeights(zeroVector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model1 = StreamingLinearRegressionWithSGD(stepSize=0.01, numIterations=1)\n",
    "#model1.setInitialWeights(Vectors.dense([0] * numFeatures))\n",
    "\n",
    "#model2 = StreamingLinearRegressionWithSGD(stepSize=1, numIterations=1)\n",
    "#model2.setInitialWeights(Vectors.dense([0] * numFeatures))\n",
    "\n",
    "\n",
    "#def parsePoint(line):\n",
    "#    values = [float(x) for x in line.split(\",\")]\n",
    "#    return LabeledPoint(label=values[0], features=Vectors.dense(values[1:]))\n",
    "\n",
    "\n",
    "#labeledStream = stream.map(lambda line: parsePoint(line))\n",
    "\n",
    "#model1.trainOn(labeledStream)\n",
    "#model2.trainOn(labeledStream)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.trainOn(trainingData)\n",
    "print(model.predictOnValues(testData.map(lambda lp: (lp.label, lp.features))))\n",
    "\n",
    "#model.predictOn(testData.map(lambda lp: lp.features))\n",
    "\n",
    "#print(model.predictOnValues(testData.map(lambda lp: (lp.label, lp.features))))\n",
    "#model.predictOnValues(testData)\n",
    "\n",
    "#predict = model.predictOn(testData.map(lambda lp: lp.features))\n",
    "#predict.foreachRDD(processToFloat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc.start()\n",
    "ssc.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
